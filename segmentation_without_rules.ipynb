{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp import PipelineCommon\n",
    "from isanlp.processor_remote import ProcessorRemote\n",
    "from isanlp.ru.processor_mystem import ProcessorMystem\n",
    "from isanlp.ru.converter_mystem_to_ud import ConverterMystemToUd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(tree, text, segments):\n",
    "    if tree.left:\n",
    "        segmentation(tree.left, text, segments)\n",
    "        segmentation(tree.right, text, segments)\n",
    "    else:\n",
    "        segments.append(text[tree.start:tree.end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = PipelineCommon([\n",
    "    (ProcessorRemote('localhost', 3334, '0'),\n",
    "     ['text'],\n",
    "     {'sentences': 'sentences',\n",
    "      'tokens': 'tokens',\n",
    "      'lemma': 'lemma',\n",
    "      'syntax_dep_tree': 'syntax_dep_tree',\n",
    "      'postag': 'ud_postag'}),\n",
    "    (ProcessorMystem(delay_init=False),\n",
    " ['tokens', 'sentences'],\n",
    "     {'postag': 'postag'}),\n",
    "    (ConverterMystemToUd(),\n",
    "     ['postag'],\n",
    "     {'morph': 'morph',\n",
    "      'postag': 'postag'}),\n",
    "    (ProcessorRemote('localhost', 3335, 'default'),\n",
    "     ['text', 'tokens', 'sentences', 'postag', 'morph', 'lemma', 'syntax_dep_tree'],\n",
    "     {'rst': 'rst'})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "names = os.listdir('../rus-human-tr')\n",
    "for name in names:\n",
    "    if name != 'segmented':\n",
    "        with open('../rus-human-tr' + '/' + name, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            text = text.split('\\n')\n",
    "            text = ' '.join(text)\n",
    "            texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Да, очень раздражает и утомляет все время сортировать мусор правильно. На кухне воняют три разных мешка для мусора. Их нужно отсортировать в разные мусорные баки. Но все же Германия производит слишком много мусора и теряется слишком много ресурсов, когда сжигается то, что на самом деле следует разделять и перерабатывать. Мы, берлинцы, должны воспользоваться шансом и стать первопроходцами в разделении отходов!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extr_pairs(tree, text):\n",
    "    pp = []\n",
    "    if tree.left:\n",
    "        pp.append([text[tree.left.start:tree.left.end],\n",
    "                   text[tree.right.start:tree.right.end], \n",
    "                   tree.relation, tree.nuclearity])\n",
    "        pp += extr_pairs(tree.left, text)\n",
    "        pp += extr_pairs(tree.right, text)\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    text = texts[i]\n",
    "    name = names[i]\n",
    "    if name.split('.')[0] in ['micro_b006', 'micro_b007', 'micro_b029', 'micro_b034', 'micro_b038']:\n",
    "        result = ppl(text)\n",
    "        tree = result['rst'][0]\n",
    "        tree.to_rs3('file.rs3')\n",
    "        text = result['text']\n",
    "        edus = extr_pairs(tree, text)\n",
    "        print(str(i)) #+ '\\n')\n",
    "        if False:\n",
    "            with open('../русский авторазметчик эде' + '/' + 'ar_' + name.split('.')[0] + '.pickle', 'wb') as f:\n",
    "                pickle.dump(edus, f)\n",
    "            with open('../русский авторазметчик эде' + '/' + 'ar_tree_' + name.split('.')[0] + '.pickle', 'wb') as f:\n",
    "                pickle.dump(tree, f)    \n",
    "        with open('../русский авторазметчик эде' + '/' + 'ar_result_' + name.split('.')[0] + '.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "#    print(extr_pairs(result['rst'][0], result['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дальше идёт черновик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(10):#len(texts)):\n",
    "    text = texts[i]\n",
    "    name = names[i]\n",
    "    result = ppl(text)\n",
    "    tree = result['rst'][0]\n",
    "    text = result['text']\n",
    "    segments = []\n",
    "    segmentation(tree, text, segments)\n",
    "    print(i + '\\n')\n",
    "    print(tree)\n",
    "    with open('../rus-human-tr/segmented' + '/' + 's_' + name, 'w') as f:\n",
    "        f.write('\\n'.join(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../rus-human-tr/segmented\\test.txt', 'w') as f:\n",
    "        f.write('\\n'.join(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "names = os.listdir('../rus-human-tr/segmented')\n",
    "for name in names:\n",
    "    with open('../rus-human-tr/segmented' + '/' + name, 'r') as f:\n",
    "        text = f.read()\n",
    "        text = text.split('\\n')\n",
    "        for edu in text:\n",
    "            texts.append(edu)\n",
    "        texts.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_excel('aaaaaa.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "trees = {}\n",
    "results = {}\n",
    "names = os.listdir(r'../русский авторазметчик эде')\n",
    "for name in names:\n",
    "    with open(r'../русский авторазметчик эде' + '/' + name, 'br') as f:\n",
    "            obj = pickle.load(f)\n",
    "            if 'tree' in name:\n",
    "                trees[name] = obj\n",
    "            else:\n",
    "                if 'result' in name:\n",
    "                    results[name] = obj\n",
    "                else:\n",
    "                    texts[name] = obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "токены: все у которых бегин правее, а енд левее. У каждого токена лемма из словаря токены — леммы, словарь один для текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tree, tokens, lemmas):\n",
    "    words = []\n",
    "    for token in tokens:\n",
    "        if tree.start <= token.begin and token.end <= tree.end:\n",
    "            words.append(lemmas[token])\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees['ar_tree_micro_k031.pickle'].right.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['ar_result_micro_k031.pickle']['sentences'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['ar_result_micro_k031.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
