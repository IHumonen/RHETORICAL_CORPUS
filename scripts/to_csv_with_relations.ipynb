{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "trees = {}\n",
    "results = {}\n",
    "names = os.listdir('../русский авторазметчик эде')\n",
    "for name in names:\n",
    "    with open('../русский авторазметчик эде' + '/' + name, 'br') as f:\n",
    "            obj = pickle.load(f)\n",
    "            if 'tree' in name:\n",
    "                trees[name] = obj\n",
    "            else:\n",
    "                if 'result' in name:\n",
    "                    results[name] = obj\n",
    "                else:\n",
    "                    texts[name] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lemmas(tokens, lemmas):\n",
    "    straight_lemmas = []\n",
    "    for sentence in lemmas:\n",
    "        for lemma in sentence:\n",
    "            straight_lemmas.append(lemma)\n",
    "    tokens_texts = []\n",
    "    for token in tokens:\n",
    "        tokens_texts.append(token.text)\n",
    "    return dict(zip(tokens_texts, straight_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tree, tokens, lemmas):\n",
    "    words = []\n",
    "    for token in tokens:\n",
    "        if tree.start <= token.begin and token.end <= tree.end:\n",
    "            words.append(lemmas[token.text])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_1(tree, tokens, lemmas):\n",
    "    return tree.relation == 'attribution'\n",
    "\n",
    "\n",
    "def rule_2(tree, tokens, lemmas):\n",
    "    if tree.relation == 'elaboration':\n",
    "        lemmas = lemmatize(tree, tokens, lemmas)\n",
    "        if 'который' in lemmas:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def rule_3(tree, tokens, lemmas):\n",
    "    if tree.relation != 'elementary':\n",
    "        lemmas = lemmatize(tree, tokens, lemmas)\n",
    "        if len(c_verbs & set(lemmas)) != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "rules = [rule_1, rule_2, rule_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions_failed(tree, rules, tokens, lemmas):\n",
    "    for rule in rules:\n",
    "        if rule(tree, tokens, lemmas):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrected(tree, rules, tokens, lemmas):\n",
    "    if conditions_failed(tree, rules, tokens, lemmas):\n",
    "        return delete_relation(tree)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_relation(tree):\n",
    "    if tree.nuclearity == 'SN':\n",
    "        attr = tree.left\n",
    "        attr.relation = 'elementary'\n",
    "        n = left_n_leaf(tree.right)\n",
    "        if (n.start - attr.end) > 1:\n",
    "            n_copy = copy.deepcopy(n)\n",
    "            n.right = n_copy \n",
    "            n.left = attr\n",
    "            n.relation = 'same-unit'\n",
    "        else:\n",
    "            n.start = attr.start\n",
    "            n.text = attr.text + n.text\n",
    "        return tree.right\n",
    "            \n",
    "    else:\n",
    "        attr = tree.right\n",
    "        attr.relation = 'elementary'\n",
    "        n = right_n_leaf(tree.left)\n",
    "        if (attr.start - n.end) > 1:\n",
    "            n_copy = copy.deepcopy(n)\n",
    "            n.left = n_copy\n",
    "            n.right = attr\n",
    "            n.relation = 'same-unit'\n",
    "        else:           \n",
    "            n.end = attr.end\n",
    "            n.text += attr.text\n",
    "        return tree.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_n_leaf(tree):\n",
    "    if tree.left:\n",
    "        if tree.nuclearity == 'SN':\n",
    "            return left_n_leaf(tree.right)\n",
    "        else:\n",
    "            return left_n_leaf(tree.left)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_n_leaf(tree):\n",
    "    if tree.right:\n",
    "        if tree.nuclearity == 'NS':\n",
    "            return right_n_leaf(tree.left)\n",
    "        else:\n",
    "            return right_n_leaf(tree.right)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(tree, text, segments, rules, tokens, lemmas):\n",
    "    if tree.relation != 'elementary':\n",
    "        tree.left = corrected(tree.left, rules, tokens, lemmas)\n",
    "        tree.right = corrected(tree.right, rules, tokens, lemmas)\n",
    "        segmentation(tree.left, text, segments, rules, tokens, lemmas)\n",
    "        segmentation(tree.right, text, segments, rules, tokens, lemmas)\n",
    "    else:\n",
    "        segments.append(text[tree.start:tree.end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_segmentation(rules):\n",
    "    segments =  []\n",
    "    for key in results:\n",
    "    #for i in range(2):\n",
    "        #key = list(results.keys())[i]\n",
    "        tree = results[key]['rst'][0]\n",
    "        text = results[key]['text']\n",
    "        tokens = results[key]['tokens']\n",
    "        lemmas = results[key]['lemma']\n",
    "        lemmas = match_lemmas(tokens, lemmas)\n",
    "        segmentation(tree, text, segments, rules, tokens, lemmas)\n",
    "        # для текстов b021,b023 и b050 автосегментатотор почему-то вернул два дерева вместо одного, поэтому нужно приделать второе дерево(там одно эде)\n",
    "        #очень костыльно конечно, но думаю так не должно быть в других текстах, какой-то сбой\n",
    "        if len(results[key]['rst']) > 1:\n",
    "            segments.append(results[key]['rst'][1].text)\n",
    "        segments.append('\\n')\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array=range(len(rules))\n",
    "power_set=[[]]\n",
    "for x in new_array:\n",
    "    for i in range(len(power_set)):\n",
    "        tmp_list = power_set[i].copy()\n",
    "        tmp_list.append(x)\n",
    "        power_set.append(tmp_list)\n",
    "power_set = power_set[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in power_set:\n",
    "    current_rules = []\n",
    "    for i in s:\n",
    "        current_rules.append(rules[i])\n",
    "    print(current_rules)\n",
    "    filename_raw = str(current_rules).split()\n",
    "    filename = []\n",
    "    for word in filename_raw:\n",
    "        if 'rule' in word:\n",
    "            filename.append(word)\n",
    "    filename = '__'.join(filename)\n",
    "    filename += '.xlsx'\n",
    "    segments = texts_segmentation(current_rules)\n",
    "    print(filename + ' сегментирован')\n",
    "    exls = pd.DataFrame(segments)\n",
    "    exls.to_excel(filename, index = False)\n",
    "    print(filename + ' записан')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
