{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код из isanlp\n",
    "\n",
    "class Segment:\n",
    "    def __init__(self, _id, parent, relname, text):\n",
    "        self.id = _id\n",
    "        self.parent = parent\n",
    "        self.relname = relname\n",
    "        self.text = text\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.parent:\n",
    "            return f'<segment id=\"{self.id}\" parent=\"{self.parent}\" relname=\"{self.relname}\">{self.text}</segment>'\n",
    "        \n",
    "        return f'<segment id=\"{self.id}\" relname=\"{self.relname}\">{self.text}</segment>'\n",
    "\n",
    "class GroupCreator:\n",
    "    def __init__(self, _id):\n",
    "        self._id = _id\n",
    "\n",
    "    def __call__(self, type, parent, relname):\n",
    "        self._id += 1\n",
    "        return Group(self._id, type, parent, relname)\n",
    "\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, _id, type, parent, relname):\n",
    "        self.id = _id\n",
    "        self.type = type\n",
    "        self.parent = parent\n",
    "        self.relname = relname\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'<group id=\"{self.id}\" type=\"{self.type}\" parent=\"{self.parent}\" relname=\"{self.relname}\"/>'\n",
    "\n",
    "\n",
    "class Root(Group):\n",
    "    def __init__(self, _id):\n",
    "        Group.__init__(self, _id, type=\"span\", parent=-1, relname=\"span\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'<group id=\"{self.id}\" type=\"{self.type}\"/>'\n",
    "\n",
    "\n",
    "class Exporter:\n",
    "    def __init__(self, encoding='utf-8'):\n",
    "        self._encoding = encoding\n",
    "    \n",
    "    def __call__(self, tree, filename):\n",
    "\n",
    "        with open(filename, 'w', encoding=self._encoding) as fo:\n",
    "            fo.write('<rst>\\n')\n",
    "            fo.write(self.make_header(tree))\n",
    "            fo.write(self.make_body(tree))\n",
    "            fo.write('</rst>')\n",
    "\n",
    "    def compile_relation_set(self, tree):\n",
    "        result = ['_'.join([tree.relation, tree.nuclearity])]\n",
    "        if not tree.left:\n",
    "            return result\n",
    "        if tree.left.left:\n",
    "            result += self.compile_relation_set(tree.left)\n",
    "        if tree.right.left:\n",
    "            result += self.compile_relation_set(tree.right)\n",
    "            \n",
    "        return result\n",
    "\n",
    "    def make_header(self, tree):\n",
    "        relations = list(set(self.compile_relation_set(tree)))\n",
    "        relations = [value if value != \"elementary__\" else \"antithesis_NN\" for value in relations]\n",
    "        result = '\\t<header>\\n'\n",
    "        result += '\\t\\t<relations>\\n'\n",
    "        for rel in relations:\n",
    "            _relname, _type = rel.split('_')[:2]\n",
    "            _type = 'multinuc' if _type == 'NN' else 'rst'\n",
    "            result += f'\\t\\t\\t<rel name=\"{_relname}\" type=\"{_type}\" />\\n'\n",
    "        result += '\\t\\t</relations>\\n'\n",
    "        result += '\\t</header>\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_groups_and_edus(self, tree):\n",
    "        groups = []\n",
    "        edus = []\n",
    "\n",
    "        if not tree.left:\n",
    "            edus.append(Segment(tree.id, parent=None, relname='antithesis', text=tree.text))\n",
    "            return groups, edus\n",
    "\n",
    "        if not tree.left.left:\n",
    "            if tree.nuclearity == \"SN\":\n",
    "                edus.append(Segment(tree.left.id, tree.right.id, tree.relation, tree.left.text))\n",
    "            elif tree.nuclearity == \"NS\":\n",
    "                edus.append(Segment(tree.left.id, tree.id, 'span', tree.left.text))\n",
    "            else:\n",
    "                edus.append(Segment(tree.left.id, tree.id, tree.relation, tree.left.text))\n",
    "        else:\n",
    "            if tree.nuclearity == \"SN\":\n",
    "                groups.append(Group(tree.left.id, 'span', tree.right.id, tree.relation))\n",
    "            elif tree.nuclearity == \"NS\":\n",
    "                groups.append(Group(tree.left.id, 'span', tree.id, 'span'))\n",
    "            else:\n",
    "                groups.append(Group(tree.left.id, 'span', tree.id, tree.relation))\n",
    "                #groups.append(Group(tree.left.id, 'multinuc', tree.id, tree.relation))\n",
    "\n",
    "            _groups, _edus = self.get_groups_and_edus(tree.left)\n",
    "            groups += _groups\n",
    "            edus += _edus\n",
    "\n",
    "        if not tree.right.left:\n",
    "            if tree.nuclearity == \"SN\":\n",
    "                edus.append(Segment(tree.right.id, tree.id, 'span', tree.right.text))\n",
    "            elif tree.nuclearity == \"NS\":\n",
    "                edus.append(Segment(tree.right.id, tree.left.id, tree.relation, tree.right.text))\n",
    "            else:\n",
    "                edus.append(Segment(tree.right.id, tree.id, tree.relation, tree.right.text))\n",
    "\n",
    "        else:\n",
    "            if tree.nuclearity == \"SN\":\n",
    "                groups.append(Group(tree.right.id, 'span', tree.id, 'span'))\n",
    "            elif tree.nuclearity == \"NS\":\n",
    "                groups.append(Group(tree.right.id, 'span', tree.left.id, tree.relation))\n",
    "            else:\n",
    "                groups.append(Group(tree.right.id, 'span', tree.id, tree.relation))\n",
    "                #groups.append(Group(tree.right.id, 'multinuc', tree.id, tree.relation))\n",
    "\n",
    "            _groups, _edus = self.get_groups_and_edus(tree.right)\n",
    "            groups += _groups\n",
    "            edus += _edus\n",
    "\n",
    "        return groups, edus\n",
    "\n",
    "    def make_body(self, tree):\n",
    "        groups, edus = self.get_groups_and_edus(tree)\n",
    "        if len(edus) > 1:\n",
    "            groups.append(Root(tree.id))\n",
    "\n",
    "        result = '\\t<body>\\n'\n",
    "        for edu in edus + groups:\n",
    "            result += '\\t\\t' + str(edu) + '\\n'\n",
    "        result += '\\t</body>\\n'\n",
    "\n",
    "        return result\n",
    "\n",
    "class ForestExporter:\n",
    "    def __init__(self, encoding='utf-8'):\n",
    "        self._encoding = encoding\n",
    "        self._tree_exporter = Exporter(self._encoding)\n",
    "    \n",
    "    def __call__(self, trees, filename):\n",
    "        \n",
    "        with open(filename, 'w', encoding=self._encoding) as fo:\n",
    "            fo.write('<rst>\\n')\n",
    "            fo.write(self.make_header(trees))\n",
    "            fo.write(self.make_body(trees))\n",
    "            fo.write('</rst>')\n",
    "        \n",
    "    def compile_relation_set(self, trees):\n",
    "        result = []\n",
    "        \n",
    "        for tree in trees:\n",
    "            result += list(set(self._tree_exporter.compile_relation_set(tree)))\n",
    "               \n",
    "        result = [value if value != \"elementary__\" else \"antithesis_NN\" for value in result]\n",
    "        return result\n",
    "    \n",
    "    def make_header(self, trees):\n",
    "        relations = list(set(self.compile_relation_set(trees)))\n",
    "\n",
    "        result = '\\t<header>\\n'\n",
    "        result += '\\t\\t<relations>\\n'\n",
    "        for rel in relations:\n",
    "            _relname, _type = rel.split('_')\n",
    "            _type = 'multinuc' if _type == 'NN' else 'rst'\n",
    "            result += f'\\t\\t\\t<rel name=\"{_relname}\" type=\"{_type}\" />\\n'\n",
    "        result += '\\t\\t</relations>\\n'\n",
    "        result += '\\t</header>\\n'\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def make_body(self, trees):\n",
    "        groups, edus = [], []\n",
    "        \n",
    "        for tree in trees:\n",
    "            _groups, _edus = self._tree_exporter.get_groups_and_edus(tree)\n",
    "            if len(_edus) > 1:\n",
    "                _groups.append(Root(tree.id))\n",
    "            groups += _groups\n",
    "            edus += _edus\n",
    "\n",
    "        result = '\\t<body>\\n'\n",
    "        for edu in edus + groups:\n",
    "            result += '\\t\\t' + str(edu) + '\\n'\n",
    "        result += '\\t</body>\\n'\n",
    "\n",
    "        return result.replace('\\u2015', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp import PipelineCommon\n",
    "from isanlp.processor_remote import ProcessorRemote\n",
    "from isanlp.ru.processor_mystem import ProcessorMystem\n",
    "from isanlp.ru.converter_mystem_to_ud import ConverterMystemToUd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Иннокентий\\Documents\\Проект_НИС_магистратура_первый курс\\русский авторазметчик эде\\tree rule_3_ar_result_micro_k017', 'br') as f:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "trees = {}\n",
    "results = {}\n",
    "names = os.listdir(r'C:\\Users\\Иннокентий\\Documents\\Проект_НИС_магистратура_первый курс\\русский авторазметчик эде')\n",
    "for name in names:\n",
    "    with open(r'C:\\Users\\Иннокентий\\Documents\\Проект_НИС_магистратура_первый курс\\русский авторазметчик эде' + '\\\\' + name, 'br') as f:\n",
    "            obj = pickle.load(f)\n",
    "            if 'tree' in name:\n",
    "                trees[name] = obj\n",
    "            else:\n",
    "                if 'result' in name:\n",
    "                    results[name] = obj\n",
    "                else:\n",
    "                    texts[name] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_verbs = set([\"хотеть\", \"подумать\", \"думать\", \"сказать\", \"решить\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lemmas(tokens, lemmas):\n",
    "    straight_lemmas = []\n",
    "    for sentence in lemmas:\n",
    "        for lemma in sentence:\n",
    "            straight_lemmas.append(lemma)\n",
    "    tokens_texts = []\n",
    "    for token in tokens:\n",
    "        tokens_texts.append(token.text)\n",
    "    return dict(zip(tokens_texts, straight_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tree, tokens, lemmas):\n",
    "    words = []\n",
    "    for token in tokens:\n",
    "        if tree.start <= token.begin and token.end <= tree.end:\n",
    "            words.append(lemmas[token.text])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_1(tree, tokens, lemmas):\n",
    "    return tree.relation == 'attribution'\n",
    "\n",
    "\n",
    "def rule_2(tree, tokens, lemmas):\n",
    "    if tree.relation == 'elaboration':\n",
    "        lemmas = lemmatize(tree, tokens, lemmas)\n",
    "        if 'который' in lemmas:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def rule_3(tree, tokens, lemmas):\n",
    "    if tree.relation != 'elementary':\n",
    "        lemmas = lemmatize(tree, tokens, lemmas)\n",
    "        if len(c_verbs & set(lemmas)) != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "rules = [rule_1, rule_2, rule_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions_failed(tree, rules, tokens, lemmas):\n",
    "    for rule in rules:\n",
    "        if rule(tree, tokens, lemmas):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrected(tree, rules, tokens, lemmas):\n",
    "    if conditions_failed(tree, rules, tokens, lemmas):\n",
    "        return delete_relation(tree)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_relation(tree):\n",
    "    if tree.nuclearity == 'SN':\n",
    "        attr = tree.left\n",
    "        attr.relation = 'elementary'\n",
    "        attr.nuclearity = 'SN'\n",
    "        n = left_n_leaf(tree.right)\n",
    "        if (n.start - attr.end) > 1:\n",
    "            n_copy = copy.deepcopy(n)\n",
    "            n.right = n_copy \n",
    "            n.left = attr\n",
    "            n.relation = 'same-unit'\n",
    "            n.nuclearity = 'NN'\n",
    "        else:\n",
    "            n.start = attr.start\n",
    "            n.text = attr.text + n.text\n",
    "        return tree.right\n",
    "            \n",
    "    else:\n",
    "        attr = tree.right\n",
    "        attr.relation = 'elementary'\n",
    "        attr.nuclearity = 'NS'\n",
    "        n = right_n_leaf(tree.left)\n",
    "        if (attr.start - n.end) > 1:\n",
    "            n_copy = copy.deepcopy(n)\n",
    "            n.left = n_copy\n",
    "            n.right = attr\n",
    "            n.relation = 'same-unit_NN'\n",
    "        else:           \n",
    "            n.end = attr.end\n",
    "            n.text += attr.text\n",
    "        return tree.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_n_leaf(tree):\n",
    "    if tree.left:\n",
    "        if tree.nuclearity == 'SN':\n",
    "            return left_n_leaf(tree.right)\n",
    "        else:\n",
    "            return left_n_leaf(tree.left)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_n_leaf(tree):\n",
    "    if tree.right:\n",
    "        if tree.nuclearity == 'NS':\n",
    "            return right_n_leaf(tree.left)\n",
    "        else:\n",
    "            return right_n_leaf(tree.right)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rs3(tree, filename):\n",
    "    exp = Exporter()\n",
    "    exp(tree, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(tree, text, segments, rules, tokens, lemmas):\n",
    "    if tree.relation != 'elementary':\n",
    "        tree.left = corrected(tree.left, rules, tokens, lemmas)\n",
    "        tree.right = corrected(tree.right, rules, tokens, lemmas)\n",
    "        segmentation(tree.left, text, segments, rules, tokens, lemmas)\n",
    "        segmentation(tree.right, text, segments, rules, tokens, lemmas)\n",
    "    else:\n",
    "        segments.append(text[tree.start:tree.end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_segmentation(rules, filename):\n",
    "    segments =  []\n",
    "    for key in results:\n",
    "    #for i in range(2):\n",
    "        #key = list(results.keys())[i]\n",
    "        tree = results[key]['rst'][0]\n",
    "        to_rs3(tree, r'C:\\Users\\Иннокентий\\Documents\\Проект_НИС_магистратура_первый курс\\русский авторазметчик эде деревья\\raw_tree ' + key.split('.')[0] + '.rs3')\n",
    "        text = results[key]['text']\n",
    "        tokens = results[key]['tokens']\n",
    "        lemmas = results[key]['lemma']\n",
    "        lemmas = match_lemmas(tokens, lemmas)\n",
    "        segmentation(tree, text, segments, rules, tokens, lemmas)\n",
    "        to_rs3(tree, r'C:\\Users\\Иннокентий\\Documents\\Проект_НИС_магистратура_первый курс\\русский авторазметчик эде деревья\\tree ' + filename + '_' + key.split('.')[0] + '.rs3')\n",
    "        # для текстов b021,b023 и b050 автосегментатотор почему-то вернул два дерева вместо одного, поэтому нужно приделать второе дерево(там одно эде)\n",
    "        #очень костыльно конечно, но думаю так не должно быть в других текстах, какой-то сбой\n",
    "        if len(results[key]['rst']) > 1:\n",
    "            segments.append(results[key]['rst'][1].text)\n",
    "        segments.append('\\n')\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array=range(len(rules))\n",
    "power_set=[[]]\n",
    "for x in new_array:\n",
    "    for i in range(len(power_set)):\n",
    "        tmp_list = power_set[i].copy()\n",
    "        tmp_list.append(x)\n",
    "        power_set.append(tmp_list)\n",
    "power_set = power_set[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for s in power_set:\n",
    "    current_rules = []\n",
    "    for i in s:\n",
    "        current_rules.append(rules[i])\n",
    "    print(current_rules)\n",
    "    filename_raw = str(current_rules).split()\n",
    "    filename = []\n",
    "    for word in filename_raw:\n",
    "        if 'rule' in word:\n",
    "            filename.append(word)\n",
    "    filename = '__'.join(filename)\n",
    "    segments = texts_segmentation(current_rules, filename)\n",
    "    filename += '.xlsx'\n",
    "    print(filename + ' сегментирован')\n",
    "    exls = pd.DataFrame(segments)\n",
    "    exls.to_excel(filename, index = False)\n",
    "    print(filename + ' записан')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дальше идёт черновик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation_rst import ForestExporter\n",
    "exporter = ForestExporter(encoding='utf8')\n",
    "exporter(results[list(results.keys())[0]]['rst'][0], 'testtesttest.rs3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[list(results.keys())[0]]['rst'][0].to_rst('testtesttest.rs3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['ar_result_micro_b001.pickle']['rst'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Exporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_groups_and_edus(results['ar_result_micro_b001.pickle']['rst'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b4,b15,,b21,b23,b50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['ar_result_micro_b004.pickle']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['ar_result_micro_b015.pickle']['rst'][0].right.left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = match_lemmas(results['ar_result_micro_k031.pickle']['tokens'], results['ar_result_micro_k031.pickle']['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['ar_result_micro_k031.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = results['ar_result_micro_k031.pickle']['rst'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize(t.left, results['ar_result_micro_k031.pickle']['tokens'], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nones(data, col1, col2):\n",
    "    l1 = list(data[col1])\n",
    "    l2 = list(data[col2])\n",
    "    l1_new = []\n",
    "    l2_new = []\n",
    "    for i in range(len()):\n",
    "        current_1 = l1[i]\n",
    "        current_2 = l2[i]\n",
    "        if current_1 == current_2:\n",
    "            l1_new.append(current_1)\n",
    "            l2_new.append(current_2)\n",
    "        else:\n",
    "            if l1 in l2:\n",
    "                l1_new.append(current_1)\n",
    "                l2_new.append(current_2)\n",
    "                l2_new.append('None')\n",
    "            elif l2 in l1:\n",
    "                l1_new.append(current_1)\n",
    "                l1_new.append('None')\n",
    "                l2_new.append(current_2)\n",
    "            else:\n",
    "                \n",
    "            \n",
    "    df.head()\n",
    "    for segment in segment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m = Mystem()\n",
    "segments = texts_segmentation(rules[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exls = pd.DataFrame(segments)\n",
    "exls.to_excel('правила_v2_attr и elab.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exls.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variants = []\n",
    "for i in range(1, len(rules)+1):\n",
    "    for j in range(i):\n",
    "        for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segments = []\n",
    "#segmentation(results['ar_result_micro_b006.pickle']['rst'][0], results['ar_result_micro_b006.pickle']['text'], segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts['ar_micro_b006.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trees['ar_tree_micro_b006.pickle'].right.start\n",
    "b = trees['ar_tree_micro_b006.pickle'].left.end\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = trees['ar_tree_micro_b006.pickle']\n",
    "print(left_n_leaf(t.left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees['ar_tree_micro_b006.pickle'].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results['ar_result_micro_b006.pickle']\n",
    "res['syntax_dep_tree'][2][5].link_name\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = ['']\n",
    "for i in range(len(res['sentenses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "trees = {}\n",
    "results = {}\n",
    "names = os.listdir(r'C:\\Users\\Иннокентий\\Documents\\Проект_НИС_магистратура_первый курс\\русский авторазметчик эде')\n",
    "for name in names:\n",
    "    with open(r'C:\\Users\\Иннокентий\\Documents\\Проект_НИС_магистратура_первый курс\\русский авторазметчик эде' + '\\\\' + name, 'br') as f:\n",
    "            obj = pickle.load(f)\n",
    "            if 'tree' in name:\n",
    "                trees[name] = obj\n",
    "            else:\n",
    "                if 'result' in name:\n",
    "                    results[name] = obj\n",
    "                else:\n",
    "                    texts[name] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(tree):\n",
    "    if tree.relation != 'elementary':\n",
    "        segmentation(tree.left)\n",
    "        segmentation(tree.right)\n",
    "    else:\n",
    "        segments.append(tree.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results[list(results.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation(res['rst'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
