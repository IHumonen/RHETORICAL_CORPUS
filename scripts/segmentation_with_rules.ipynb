{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "segmentation_with_rules.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGsw2Q6hwXFq",
        "outputId": "19ac36f1-59e4-480a-a9ec-6538818e7294"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC42bd6twvPm"
      },
      "source": [
        "#import os\n",
        "#os.chdir('gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADE5QCHQHx94"
      },
      "source": [
        "# установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cu102\n",
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "pFAX4FHuC2gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install syntax_ru_syntagrus_bert\n",
        "!python -m deeppavlov install squad_bert\n",
        "!pip install tensorflow==1.14 \n",
        "!pip install russian_tagsets"
      ],
      "metadata": {
        "id": "8f1qCiHjDD0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import build_model, configs\n",
        "model = build_model(\"ru_syntagrus_joint_parsing\", download=True)"
      ],
      "metadata": {
        "id": "wKv7mKecDOtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my0DKd_dH1jQ"
      },
      "source": [
        "# загрузка подвыборок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqOPVHq5tDrM"
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('train_names.txt','r', encoding='utf-8')\n",
        "train_names = []\n",
        "for line in f.readlines():\n",
        "  train_names.append(line[:-1])\n",
        "f.close()"
      ],
      "metadata": {
        "id": "MPozToOcFjoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNuumkR4MEyo"
      },
      "source": [
        "f = open('test_names.txt','r', encoding='utf-8')\n",
        "test_names = []\n",
        "for line in f.readlines():\n",
        "  test_names.append(line[:-1])\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32mun8bytDrc"
      },
      "source": [
        "texts = {}\n",
        "trees = {}\n",
        "results = {}\n",
        "\n",
        "for name in test_names: # или train_names\n",
        "  try:\n",
        "    #указываем путь к pickle файлам с разметкой русского авторазметчика\n",
        "    with open(r'corpus/Russian RST parser/pickle' + '/' + name, 'br') as f:\n",
        "      obj = pickle.load(f)\n",
        "      if 'tree' in name:\n",
        "        trees[name] = obj\n",
        "      else:\n",
        "        if 'result' in name:\n",
        "          results[name] = obj\n",
        "        else:\n",
        "          texts[name] = obj\n",
        "  except:\n",
        "    continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyZMpvZvL4o8",
        "outputId": "5553bfa9-d731-463a-8d46-ca3722a02a6c"
      },
      "source": [
        "#train texts\n",
        "len(texts.keys()), len(results.keys()), len(trees.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79, 79, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSjXk3SQhQoF",
        "outputId": "4a6e9874-bc9c-42ce-b133-7905a8a28d15"
      },
      "source": [
        "#test texts\n",
        "len(texts.keys()), len(results.keys()), len(trees.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 30, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# адаптация русского авторазметчика"
      ],
      "metadata": {
        "id": "rBM5iTlTkyvV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApP8zWT9tDre"
      },
      "source": [
        "c_verbs = set([\"хотеть\", \"подумать\", \"думать\", \"сказать\", \"решить\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu3hHMrwtDrf"
      },
      "source": [
        "def match_lemmas(tokens: list, lemmas: list) -> dict:\n",
        "    \"\"\"Сопоставляет токены с леммами\"\"\"\n",
        "\n",
        "    straight_lemmas = []\n",
        "    for sentence in lemmas:\n",
        "        for lemma in sentence:\n",
        "            straight_lemmas.append(lemma)\n",
        "    tokens_texts = []\n",
        "    for token in tokens:\n",
        "        tokens_texts.append(token.text)\n",
        "    return dict(zip(tokens_texts, straight_lemmas))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ph-5YAHtDrg"
      },
      "source": [
        "def lemmatize(tree: dict, tokens: list, lemmas: list) -> list:\n",
        "    \"\"\"Возвращает леммы токенов в дереве\"\"\"\n",
        "    \n",
        "    words = []\n",
        "    for token in tokens:\n",
        "        if tree.start <= token.begin and token.end <= tree.end:\n",
        "            words.append(lemmas[token.text])\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy4_HlPktDrh"
      },
      "source": [
        "def rule_1(tree: dict, tokens: list, lemmas: list) -> bool:\n",
        "    \"\"\"Проверяет, есть ли отношение 'аттрибут/источник' \"\"\"\n",
        "\n",
        "    return tree.relation == 'attribution'\n",
        "\n",
        "\n",
        "def rule_2(tree: dict, tokens: list, lemmas: list) -> bool:\n",
        "    \"\"\"Проверяет наличие слова 'который' при отношении 'детализация'\n",
        "       Если оно есть, сегмент отделяться не будет\"\"\"\n",
        "\n",
        "    if tree.relation == 'elaboration':\n",
        "        lemmas = lemmatize(tree, tokens, lemmas)\n",
        "        if 'который' in lemmas:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def rule_3(tree: dict, tokens: list, lemmas: list) -> bool:\n",
        "    \"\"\"Проверяет наличие когнитивного глагола в сегменте,\n",
        "       Если он есть, сегмент отделяться не будет\"\"\"\n",
        "\n",
        "    if tree.relation != 'elementary':\n",
        "        lemmas = lemmatize(tree, tokens, lemmas)\n",
        "        if len(c_verbs & set(lemmas)) != 0:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxCx1ebvfDiE"
      },
      "source": [
        "def rule_4(edu: str) -> bool:\n",
        "  \"\"\"Проверяет сегмент на наличие предложной группы\"\"\"\n",
        "\n",
        "  for parse in model([edu]):\n",
        "    sent_info = []\n",
        "    row = parse.split('\\t_\\n')\n",
        "\n",
        "    for i in row:\n",
        "      inf = i.split('\\t')\n",
        "      sent_info.append(inf)\n",
        "\n",
        "  get_pos = []\n",
        "\n",
        "  for info in sent_info:\n",
        "    if info[3] in ['ADP', 'VERB', 'PUNCT']:\n",
        "      get_pos.append([info[0], info[3], info[6]])\n",
        "\n",
        "  for tag in get_pos:\n",
        "    if tag[1] == 'ADP' and tag[0] == '1':\n",
        "      tags = [j[1] for j in get_pos]\n",
        "      if 'VERB' not in tags:\n",
        "        return True\n",
        "\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cJ2Z3tLq41D"
      },
      "source": [
        "def tree_check(tree: dict) ->  bool:\n",
        "  \"\"\"Дополнительная проверка на содержание сегментов\"\"\"\n",
        "\n",
        "  if tree != None:\n",
        "    if tree.left == None and tree.right == None:\n",
        "      return rule_4(tree.text)\n",
        "\n",
        "  return False\n",
        "\n",
        "def rule_morph(tree: dict, tokens: list, lemmas: list) -> bool:\n",
        "  \"\"\"Проверяет дерево на наличие предложной группы\"\"\"\n",
        "\n",
        "  res_left = tree_check(tree.left)\n",
        "  res_right = tree_check(tree.right)\n",
        "  if res_left == True or res_right == True:\n",
        "    return True\n",
        "\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af2cDfS2tDri"
      },
      "source": [
        "def conditions_failed(tree: dict, rules: list, tokens: list, lemmas: list) -> bool:\n",
        "    \"\"\"Проверяет подпадает ли сегмент под условия правил\"\"\"\n",
        "\n",
        "    for rule in rules:\n",
        "        if rule(tree, tokens, lemmas):\n",
        "            return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmA8pRhtDrj"
      },
      "source": [
        "def corrected(tree: dict, rules: list, tokens: list, lemmas: list) -> dict:\n",
        "    \"\"\"Объединяет сегменты, удаляя отношение между ними, при положительном результате проверки на правила\"\"\"\n",
        "\n",
        "    if conditions_failed(tree, rules, tokens, lemmas):\n",
        "        return delete_relation(tree)\n",
        "    else:\n",
        "        return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugTQqcpVtDrm"
      },
      "source": [
        "def delete_relation(tree: dict) -> dict:\n",
        "    \"\"\"Удаляет отношение\"\"\"\n",
        "    \n",
        "    if tree.nuclearity == 'SN':\n",
        "        attr = tree.left\n",
        "        attr.relation = 'elementary'\n",
        "        n = left_n_leaf(tree.right)\n",
        "        if (n.start - attr.end) > 1:\n",
        "            n_copy = copy.deepcopy(n)\n",
        "            n.right = n_copy \n",
        "            n.left = attr\n",
        "            n.relation = 'same-unit'\n",
        "        else:\n",
        "            n.start = attr.start\n",
        "            n.text = attr.text + n.text\n",
        "        return tree.right\n",
        "            \n",
        "    else:\n",
        "        attr = tree.right\n",
        "        attr.relation = 'elementary'\n",
        "        n = right_n_leaf(tree.left)\n",
        "        if (attr.start - n.end) > 1:\n",
        "            n_copy = copy.deepcopy(n)\n",
        "            n.left = n_copy\n",
        "            n.right = attr\n",
        "            n.relation = 'same-unit'\n",
        "        else:           \n",
        "            n.end = attr.end\n",
        "            n.text += attr.text\n",
        "        return tree.left"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1941wnYtDrn"
      },
      "source": [
        "def left_n_leaf(tree: dict) -> dict:\n",
        "    \"\"\"Возвращает левую ветвь дерева\"\"\"\n",
        "\n",
        "    if tree.left:\n",
        "        if tree.nuclearity == 'SN':\n",
        "            return left_n_leaf(tree.right)\n",
        "        else:\n",
        "            return left_n_leaf(tree.left)\n",
        "    else:\n",
        "        return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cToKv-PtDro"
      },
      "source": [
        "def right_n_leaf(tree: dict) -> dict:\n",
        "  \"\"\"Возвращает правую ветвь дерева\"\"\"\n",
        "\n",
        "    if tree.left:\n",
        "        if tree.nuclearity == 'NS':\n",
        "            return right_n_leaf(tree.left)\n",
        "        else:\n",
        "            return right_n_leaf(tree.right)\n",
        "    else:\n",
        "        return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZQ9WI_ttDrp"
      },
      "source": [
        "def segmentation(tree: dict, text: str, segments: list, rules: list, tokens: list, lemmas: list) -> None:\n",
        "    \"\"\"Пересегментирует деревья\"\"\"\n",
        "\n",
        "    if tree.relation != 'elementary':\n",
        "        tree.left = corrected(tree.left, rules, tokens, lemmas)\n",
        "        tree.right = corrected(tree.right, rules, tokens, lemmas)\n",
        "        segmentation(tree.left, text, segments, rules, tokens, lemmas)\n",
        "        segmentation(tree.right, text, segments, rules, tokens, lemmas)\n",
        "    else:\n",
        "          segments.append(text[tree.start:tree.end])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hew964HdtDrp"
      },
      "source": [
        "def texts_segmentation(rules: list) -> list:\n",
        "    \"\"\"Возвращает сегменты\"\"\"\n",
        "\n",
        "    segments =  []\n",
        "    for key in results:\n",
        "        tree = results[key]['rst'][0]\n",
        "        text = results[key]['text']\n",
        "        tokens = results[key]['tokens']\n",
        "        lemmas = results[key]['lemma']\n",
        "        lemmas = match_lemmas(tokens, lemmas)\n",
        "        segmentation(tree, text, segments, rules, tokens, lemmas)\n",
        "        #для текстов b021,b023 и b050 автосегментатотор почему-то вернул два дерева вместо одного, поэтому нужно приделать второе дерево(там одно эде)\n",
        "        #очень костыльно конечно, но думаю так не должно быть в других текстах, какой-то сбой\n",
        "        if len(results[key]['rst']) > 1:\n",
        "            segments.append(results[key]['rst'][1].text)\n",
        "        segments.append('\\n')\n",
        "        \n",
        "    return segments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CbYKW-ZlfDU"
      },
      "source": [
        "rules = [rule_1, rule_2, rule_3, rule_morph]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1PXhvqFtDrq"
      },
      "source": [
        "new_array=range(len(rules))\n",
        "power_set=[[]]\n",
        "for x in new_array:\n",
        "    for i in range(len(power_set)):\n",
        "        tmp_list = power_set[i].copy()\n",
        "        tmp_list.append(x)\n",
        "        power_set.append(tmp_list)\n",
        "power_set = power_set[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdwMukoTsgwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa83aea-046f-4ac8-872b-eb2769c07142"
      },
      "source": [
        "%%time\n",
        "for s in power_set[:9]:\n",
        "    current_rules = []\n",
        "    for i in s:\n",
        "        current_rules.append(rules[i])\n",
        "    print(current_rules)\n",
        "    filename_raw = str(current_rules).split()\n",
        "    filename = []\n",
        "    for word in filename_raw:\n",
        "        if 'rule' in word:\n",
        "            filename.append(word)\n",
        "    filename = '__'.join(filename)\n",
        "    filename += '.xlsx'\n",
        "    segments = texts_segmentation(current_rules)\n",
        "    print(filename + ' сегментирован')\n",
        "    exls = pd.DataFrame(segments)\n",
        "    exls.to_excel(filename, index = False)\n",
        "    print(filename + ' записан')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<function rule_1 at 0x7f3ff7f95320>]\n",
            "rule_1.xlsx сегментирован\n",
            "rule_1.xlsx записан\n",
            "[<function rule_2 at 0x7f3ff7f95200>]\n",
            "rule_2.xlsx сегментирован\n",
            "rule_2.xlsx записан\n",
            "[<function rule_1 at 0x7f3ff7f95320>, <function rule_2 at 0x7f3ff7f95200>]\n",
            "rule_1__rule_2.xlsx сегментирован\n",
            "rule_1__rule_2.xlsx записан\n",
            "[<function rule_3 at 0x7f3ff7f95560>]\n",
            "rule_3.xlsx сегментирован\n",
            "rule_3.xlsx записан\n",
            "[<function rule_1 at 0x7f3ff7f95320>, <function rule_3 at 0x7f3ff7f95560>]\n",
            "rule_1__rule_3.xlsx сегментирован\n",
            "rule_1__rule_3.xlsx записан\n",
            "[<function rule_2 at 0x7f3ff7f95200>, <function rule_3 at 0x7f3ff7f95560>]\n",
            "rule_2__rule_3.xlsx сегментирован\n",
            "rule_2__rule_3.xlsx записан\n",
            "[<function rule_1 at 0x7f3ff7f95320>, <function rule_2 at 0x7f3ff7f95200>, <function rule_3 at 0x7f3ff7f95560>]\n",
            "rule_1__rule_2__rule_3.xlsx сегментирован\n",
            "rule_1__rule_2__rule_3.xlsx записан\n",
            "[<function rule_morph at 0x7f4002b8d830>]\n",
            "rule_morph.xlsx сегментирован\n",
            "rule_morph.xlsx записан\n",
            "[<function rule_1 at 0x7f3ff7f95320>, <function rule_morph at 0x7f4002b8d830>]\n",
            "rule_1__rule_morph.xlsx сегментирован\n",
            "rule_1__rule_morph.xlsx записан\n",
            "CPU times: user 25min 19s, sys: 7min 25s, total: 32min 44s\n",
            "Wall time: 20min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}